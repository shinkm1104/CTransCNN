{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding disease labels: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 31.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping image file paths...\n",
      "Number of images with valid paths: 112120\n",
      "Creating balanced test set by disease...\n",
      "Test dataset size: 22637 (20% of total data)\n",
      "Creating data loaders...\n",
      "Number of items in test dataset: 18110\n",
      "Loading new model...\n",
      "Error loading with load_learner: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "Error loading with state_dict: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "Trying default fastai loader...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/userHome/userhome4/kyoungmin/code/Xray/NIH_EXP/Project/pkl_data/all_labels_14.pkl.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 128\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Î∞©Î≤ï 1: fastaiÏùò load_learner ÏÇ¨Ïö© (.pkl ÌååÏùº Î°úÎìú)\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     learn \u001b[38;5;241m=\u001b[39m \u001b[43mload_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEW_MODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Model loaded successfully using load_learner!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/fastai/learner.py:448\u001b[0m, in \u001b[0;36mload_learner\u001b[0;34m(fname, cpu, pickle_module)\u001b[0m\n\u001b[1;32m    447\u001b[0m map_loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cpu \u001b[38;5;28;01melse\u001b[39;00m default_device()\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: res \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_loc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_module\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/torch/serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/torch/serialization.py:1034\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m-> 1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 136\u001b[0m\n\u001b[1;32m    135\u001b[0m learn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 136\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEW_MODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Î°úÎìúÎêú Îç∞Ïù¥ÌÑ∞Í∞Ä state_dict ÌòïÌÉúÏù∏ÏßÄ ÌôïÏù∏\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/torch/serialization.py:815\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/torch/serialization.py:1034\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m-> 1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 151\u001b[0m\n\u001b[1;32m    149\u001b[0m         learn \u001b[38;5;241m=\u001b[39m vision_learner(test_dls, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoatnet_2_rw_224\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[accuracy_multi])\n\u001b[1;32m    150\u001b[0m         learn\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 151\u001b[0m         \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNEW_MODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Model loaded successfully using default fastai loader!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# ----- Ïù¥Ìïò ÏΩîÎìúÎäî ÎèôÏùº -----\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Î™®Îç∏ ÌèâÍ∞Ä\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/fastai/learner.py:422\u001b[0m, in \u001b[0;36mload\u001b[0;34m(self, file, device, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m file \u001b[38;5;241m=\u001b[39m join_path_file(file, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_dir, ext\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    421\u001b[0m distrib_barrier()\n\u001b[0;32m--> 422\u001b[0m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/fastai/learner.py:53\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(file, model, opt, with_opt, device, strict, **torch_load_kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m): device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, device)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 53\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtorch_load_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m hasopt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(state)\u001b[38;5;241m==\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     55\u001b[0m model_state \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m hasopt \u001b[38;5;28;01melse\u001b[39;00m state\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/userHome/userhome4/kyoungmin/code/Xray/NIH_EXP/Project/pkl_data/all_labels_14.pkl.pth'"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "DATA_PATH = '/userHome/userhome4/kyoungmin/code/Xray/dataset'\n",
    "OUTPUT_DIR = '/userHome/userhome4/kyoungmin/code/Xray/CoAtNet/output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ÏÉà Î™®Îç∏ Í≤ΩÎ°ú ÏÑ§Ï†ï (.pkl ÌååÏùº)\n",
    "NEW_MODEL_PATH = '/userHome/userhome4/kyoungmin/code/Xray/NIH_EXP/Project/pkl_data/all_labels_14.pkl'  # <-- Ïó¨Í∏∞Ïóê ÏÉà Î™®Îç∏ Í≤ΩÎ°ú ÏûÖÎ†•\n",
    "\n",
    "# ÏãúÎìú ÏÑ§Ï†ï\n",
    "SEED = 85\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "# GPU ÏÑ§Ï†ï\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ÏßàÎ≥ë Î†àÏù¥Î∏î Ï†ïÏùò\n",
    "disease_labels = ['No finding', 'Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', \n",
    "                  'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n",
    "                  'Cardiomegaly', 'Nodule', 'Mass', 'Hernia']\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "print(\"Loading data...\")\n",
    "labels_df = pd.read_csv(f'{DATA_PATH}/Data_Entry_2017.csv')\n",
    "labels_df.columns = ['Image_Index', 'Finding_Labels', 'Follow_Up_#', 'Patient_ID',\n",
    "                    'Patient_Age', 'Patient_Gender', 'View_Position',\n",
    "                    'Original_Image_Width', 'Original_Image_Height',\n",
    "                    'Original_Image_Pixel_Spacing_X',\n",
    "                    'Original_Image_Pixel_Spacing_Y', 'dfd']\n",
    "\n",
    "# ÏßàÎ≥ë Î†àÏù¥Î∏î Ïõê-Ìï´ Ïù∏ÏΩîÎî©\n",
    "for disease in tqdm(disease_labels, desc=\"Encoding disease labels\"):\n",
    "    labels_df[disease] = labels_df['Finding_Labels'].map(lambda result: 1 if disease in result else 0)\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú Îß§Ìïë\n",
    "print(\"Mapping image file paths...\")\n",
    "num_glob = glob(f'{DATA_PATH}/*/images/*.png')\n",
    "img_path = {os.path.basename(x): x for x in num_glob}\n",
    "labels_df['Paths'] = labels_df['Image_Index'].map(img_path.get)\n",
    "\n",
    "# Í≤ΩÎ°úÍ∞Ä Ïú†Ìö®Ìïú Îç∞Ïù¥ÌÑ∞Îßå ÌïÑÌÑ∞ÎßÅ\n",
    "valid_paths = labels_df['Paths'].notna()\n",
    "labels_df = labels_df[valid_paths].reset_index(drop=True)\n",
    "print(f\"Number of images with valid paths: {len(labels_df)}\")\n",
    "\n",
    "# Î≥ëÎ≥ÄÎ≥ÑÎ°ú Í∑†Ìòï Ïû°Ìûå ÌÖåÏä§Ìä∏ÏÖã ÏÉùÏÑ±\n",
    "print(\"Creating balanced test set by disease...\")\n",
    "test_indices = set()\n",
    "\n",
    "for disease in disease_labels:\n",
    "    # Í∞Å ÏßàÎ≥ëÏóê ÎåÄÌï¥ ÏñëÏÑ±(1) ÏÉòÌîåÍ≥º ÏùåÏÑ±(0) ÏÉòÌîåÏùÑ Ï∞æÏùå\n",
    "    positive_samples = labels_df[labels_df[disease] == 1].index.tolist()\n",
    "    negative_samples = labels_df[labels_df[disease] == 0].index.tolist()\n",
    "    \n",
    "    # ÏñëÏÑ± ÏÉòÌîåÏùò 50%Î•º ÌÖåÏä§Ìä∏ÏÖãÏúºÎ°ú ÏÑ†ÌÉù\n",
    "    pos_test_size = min(len(positive_samples) // 2, 1000)  # ÏµúÎåÄ 1,000Í∞ú Ï†úÌïú\n",
    "    pos_test_indices = random.sample(positive_samples, pos_test_size)\n",
    "    \n",
    "    # ÏùåÏÑ± ÏÉòÌîåÎèÑ ÎπÑÏä∑Ìïú ÏàòÎ•º ÌÖåÏä§Ìä∏ÏÖãÏúºÎ°ú ÏÑ†ÌÉù\n",
    "    neg_test_size = min(len(negative_samples) // 10, pos_test_size)  # ÏñëÏÑ± ÏÉòÌîå ÏàòÏôÄ ÎπÑÏä∑ÌïòÍ≤å\n",
    "    neg_test_indices = random.sample(negative_samples, neg_test_size)\n",
    "    \n",
    "    # ÌÖåÏä§Ìä∏ Ïù∏Îç±Ïä§Ïóê Ï∂îÍ∞Ä\n",
    "    test_indices.update(pos_test_indices)\n",
    "    test_indices.update(neg_test_indices)\n",
    "\n",
    "# ÌÖåÏä§Ìä∏ÏÖãÍ≥º ÌïôÏäµÏÖã Î∂ÑÎ¶¨\n",
    "test_indices = list(test_indices)\n",
    "test_df = labels_df.loc[test_indices].reset_index(drop=True)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÎπÑÏú® Í≥ÑÏÇ∞\n",
    "total_dataset_size = len(labels_df)\n",
    "test_dataset_size = len(test_df)\n",
    "dataset_percentage = int((test_dataset_size / total_dataset_size) * 100)\n",
    "print(f\"Test dataset size: {len(test_df)} ({dataset_percentage}% of total data)\")\n",
    "\n",
    "# DataBlock ÏÑ§Ï†ï\n",
    "item_transforms = [Resize((224, 224))]\n",
    "batch_transforms = [Normalize.from_stats(*imagenet_stats)]\n",
    "\n",
    "def get_x(row):\n",
    "    return row['Paths']\n",
    "\n",
    "def get_y(row):\n",
    "    labels = row[disease_labels].tolist()\n",
    "    return labels\n",
    "\n",
    "test_dblock = DataBlock(\n",
    "    blocks=(ImageBlock, MultiCategoryBlock(encoded=True, vocab=disease_labels)),\n",
    "    get_x=get_x,\n",
    "    get_y=get_y,\n",
    "    item_tfms=item_transforms,\n",
    "    batch_tfms=batch_transforms\n",
    ")\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎçî ÏÉùÏÑ±\n",
    "print(\"Creating data loaders...\")\n",
    "test_dls = test_dblock.dataloaders(test_df, bs=32, shuffle=False)\n",
    "print(f\"Number of items in test dataset: {len(test_dls.train.dataset)}\")\n",
    "\n",
    "# ----- Î™®Îç∏ Î°úÎìú Î∂ÄÎ∂Ñ (ÏàòÏ†ïÎê®) -----\n",
    "print(\"Loading new model...\")\n",
    "try:\n",
    "    # Î∞©Î≤ï 1: fastaiÏùò load_learner ÏÇ¨Ïö© (.pkl ÌååÏùº Î°úÎìú)\n",
    "    learn = load_learner(NEW_MODEL_PATH)\n",
    "    print(\"‚úÖ Model loaded successfully using load_learner!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading with load_learner: {e}\")\n",
    "    try:\n",
    "        # Î∞©Î≤ï 2: Î™®Îç∏ Íµ¨Ï°∞ ÏÉùÏÑ± ÌõÑ state_dict Î°úÎìú\n",
    "        learn = vision_learner(test_dls, 'coatnet_2_rw_224', metrics=[accuracy_multi])\n",
    "        learn.model.to(device)\n",
    "        state_dict = torch.load(NEW_MODEL_PATH, map_location=device)\n",
    "        \n",
    "        # Î°úÎìúÎêú Îç∞Ïù¥ÌÑ∞Í∞Ä state_dict ÌòïÌÉúÏù∏ÏßÄ ÌôïÏù∏\n",
    "        if hasattr(state_dict, 'model'):\n",
    "            learn.model.load_state_dict(state_dict.model)\n",
    "        else:\n",
    "            learn.model.load_state_dict(state_dict)\n",
    "        print(\"‚úÖ Model loaded successfully using load_state_dict!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Error loading with state_dict: {e2}\")\n",
    "        print(\"Trying default fastai loader...\")\n",
    "        \n",
    "        # Î∞©Î≤ï 3: Í∏∞Î≥∏ fastai Î°úÎçî ÏÇ¨Ïö©\n",
    "        learn = vision_learner(test_dls, 'coatnet_2_rw_224', metrics=[accuracy_multi])\n",
    "        learn.model.to(device)\n",
    "        learn.load(NEW_MODEL_PATH)\n",
    "        print(\"‚úÖ Model loaded successfully using default fastai loader!\")\n",
    "\n",
    "# ----- Ïù¥Ìïò ÏΩîÎìúÎäî ÎèôÏùº -----\n",
    "# Î™®Îç∏ ÌèâÍ∞Ä\n",
    "print(\"Making predictions...\")\n",
    "learn.model.eval()\n",
    "\n",
    "# ÏòàÏ∏° ÏàòÌñâ\n",
    "with torch.no_grad():\n",
    "    preds, targs = learn.get_preds(dl=test_dls.train)\n",
    "print(f\"Targets tensor shape: {targs.shape}\")\n",
    "print(f\"Predictions tensor shape: {preds.shape}\")\n",
    "\n",
    "# PyTorch Tensor ‚Üí NumPy Î∞∞Ïó¥ Î≥ÄÌôò\n",
    "probs = preds.detach().cpu().numpy()\n",
    "targets = targs.detach().cpu().numpy()\n",
    "\n",
    "# Î≥ëÎ≥ÄÎ≥Ñ ÏÉòÌîå Í∞úÏàò Ï∂úÎ†•\n",
    "disease_counts = np.sum(targets, axis=0)\n",
    "disease_count_dict = dict(zip(disease_labels, disease_counts))\n",
    "print(\"\\nüìå Actual disease sample counts:\")\n",
    "for disease, count in disease_count_dict.items():\n",
    "    print(f\"{disease}: {int(count)} samples\")\n",
    "\n",
    "# (Ïù¥Ìïò Î∂ÑÏÑù ÏΩîÎìúÎäî ÎèôÏùºÌïòÍ≤å Ïú†ÏßÄ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/train_val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     14\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m train_val_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../data/train_val.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Extract the paths and labels\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/xray/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/train_val.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "train_val_df = pd.read_csv(\"../../data/train_val.csv\")\n",
    "test_df = pd.read_csv(\"../../data/test.csv\")\n",
    "\n",
    "# Extract the paths and labels\n",
    "disease_labels = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', 'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening',\n",
    "'Cardiomegaly', 'Nodule', 'Mass', 'Hernia', 'No Finding']\n",
    "train_val_labels = train_val_df[disease_labels].values\n",
    "test_labels = test_df[disease_labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Pickle ÌååÏùºÏóêÏÑú numpy Î∞∞Ïó¥ Î∂àÎü¨Ïò§Í∏∞\n",
    "with open('/userHome/userhome4/kyoungmin/code/Xray/CTransCNN/pkl_data/all_labels_14.pkl', 'rb') as file:\n",
    "    all_labels = pickle.load(file)\n",
    "    \n",
    "with open('/userHome/userhome4/kyoungmin/code/Xray/CTransCNN/pkl_data/all_outputs.pkl', 'rb') as file:\n",
    "    all_outputs = pickle.load(file)\n",
    "    \n",
    "with open('/userHome/userhome4/kyoungmin/code/Xray/CTransCNN/pkl_data/binary_outputs.pkl', 'rb') as file:\n",
    "    binary_outputs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disease_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# one error check\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m value_dict \u001b[38;5;241m=\u001b[39m {i:\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdisease_labels\u001b[49m}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m all_outputs:\n\u001b[1;32m      4\u001b[0m     value_dict[disease_labels[\u001b[38;5;28mlist\u001b[39m(b)\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(b))]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'disease_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# one error check\n",
    "value_dict = {i:0 for i in disease_labels}\n",
    "for b in all_outputs:\n",
    "    value_dict[disease_labels[list(b).index(max(b))]] += 1\n",
    "\n",
    "value_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
